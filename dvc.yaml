stages:
  data_ingestion:
    cmd: python src/data/data_ingestion.py
    deps:
      - src/data/data_ingestion.py
      - data/raw/Reddit_Data.csv
    params:
      - data_ingestion
    outs:
      # We output to 'processed' now, not 'raw'
      - data/processed/train.csv
      - data/processed/test.csv

  data_preprocessing:
    cmd: python src/data/data_preprocessing.py
    deps:
      - src/data/data_preprocessing.py
      # The input here comes from the output of data_ingestion
      - data/processed/train.csv
      - data/processed/test.csv
    params:
      - preprocessing
    outs:
      # These are the cleaned files ready for vectorization
      - data/processed/train_clean.csv
      - data/processed/test_clean.csv

  build_features:
    cmd: python src/features/build_features.py --config params.yaml
    deps:
      - src/features/build_features.py
      - data/processed/train_clean.csv  
      - data/processed/test_clean.csv
    params:
      - build_features.max_features
      - build_features.ngram_range
    outs:
      - data/processed/train_features.pkl
      - data/processed/test_features.pkl
      - data/processed/tfidf_vectorizer.pkl
  
  train_model:
    cmd: python src/models/train_model.py --config params.yaml
    deps:
      - src/models/train_model.py
      - data/processed/train_features.pkl
    params:
      - model_params.base_model_lgbm
      - model_params.base_model_logreg
      - model_params.meta_model_knn
    outs:
      - models/stacking_model.pkl
  
  evaluate_model:
    cmd: python src/models/evaluate_model.py --config params.yaml
    deps:
      - src/models/evaluate_model.py
      - models/stacking_model.pkl
      - data/processed/test_features.pkl
    metrics:
      - metrics.json:
          cache: false

  